{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cosyvoice.cli.cosyvoice import CosyVoice, CosyVoice2\n",
    "from cosyvoice.utils.file_utils import load_wav\n",
    "import torchaudio\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import random\n",
    "import json\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "\n",
    "def display_audio_path(wav_path):\n",
    "    display(Audio(wav_path))\n",
    "\n",
    "\n",
    "def display_audio(wav, rate=24000):\n",
    "    display(Audio(wav, rate=rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosyvoice = CosyVoice(\"pretrained_models/CosyVoice-300M\")\n",
    "\n",
    "cosyvoice2 = CosyVoice2(\n",
    "    \"pretrained_models/CosyVoice2-0.5B\", load_jit=True, load_onnx=False, load_trt=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosyvoice = CosyVoice(\"pretrained_models/CosyVoice-300M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_tts(\n",
    "    target_text, prompt_speech_wav_path, prompt_text, model_name=\"cosyvoice2\"\n",
    "):\n",
    "    if model_name == \"cosyvoice\":\n",
    "        prompt_speech_16k = load_wav(prompt_speech_wav_path, 16000)\n",
    "        for i, j in enumerate(\n",
    "            cosyvoice.inference_zero_shot(\n",
    "                target_text,\n",
    "                prompt_text,\n",
    "                prompt_speech_16k,\n",
    "                stream=False,\n",
    "            )\n",
    "        ):\n",
    "            return j[\"tts_speech\"]\n",
    "\n",
    "    if model_name == \"cosyvoice2\":\n",
    "        prompt_speech_16k = load_wav(prompt_speech_wav_path, 16000)\n",
    "        for i, j in enumerate(\n",
    "            cosyvoice2.inference_zero_shot(\n",
    "                target_text,\n",
    "                prompt_text,\n",
    "                prompt_speech_16k,\n",
    "                stream=False,\n",
    "                text_frontend=False,\n",
    "            )\n",
    "        ):\n",
    "            return j[\"tts_speech\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_instruct_tts(\n",
    "    target_text, prompt_speech_wav_path, instruction, model_name=\"cosyvoice2\"\n",
    "):\n",
    "    if model_name == \"cosyvoice2\":\n",
    "        prompt_speech_16k = load_wav(prompt_speech_wav_path, 16000)\n",
    "        for i, j in enumerate(\n",
    "            cosyvoice2.inference_instruct2(\n",
    "                target_text,\n",
    "                instruction,\n",
    "                prompt_speech_16k,\n",
    "                stream=False,\n",
    "                text_frontend=False,\n",
    "            )\n",
    "        ):\n",
    "            return j[\"tts_speech\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/storage/zhangxueyao/workspace/SpeechGenerationYC/EvalSet/tts/\"\n",
    "\n",
    "\n",
    "def get_text_wav_pairs(root):\n",
    "    with open(os.path.join(root, \"evalset.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        evalset = json.load(f)\n",
    "\n",
    "    pairs = []\n",
    "    for item in evalset:\n",
    "        for t in [\"input\", \"prompt\"]:\n",
    "            duration = item[t][\"duration\"]\n",
    "            if duration < 5:\n",
    "                continue\n",
    "\n",
    "            text = item[t][\"text\"]\n",
    "            uid = item[t][\"uid\"]\n",
    "\n",
    "            wav_path = os.path.join(root, \"wav\", f\"{uid}.wav\")\n",
    "            pairs.append((text, wav_path))\n",
    "    return pairs\n",
    "\n",
    "\n",
    "en_pairs = get_text_wav_pairs(os.path.join(root, \"seedtts_en\"))\n",
    "zh_pairs = get_text_wav_pairs(os.path.join(root, \"seedtts_zh\"))\n",
    "\n",
    "len(en_pairs), len(zh_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_switching_examples = [\n",
    "    # 工作场合\n",
    "    \"我待会要去开个meeting\",\n",
    "    \"这个project的deadline是下周五\",\n",
    "    \"你要不要来我们team?\",\n",
    "    \"我们先sync一下进度吧\",\n",
    "    \"麻烦你发个email给我\",\n",
    "    # 学习场合\n",
    "    \"我今天要去library学习\",\n",
    "    \"这道题太difficult了\",\n",
    "    \"下周有个presentation要准备\",\n",
    "    \"我的paper被reject了\",\n",
    "    \"你的GPA多少？\",\n",
    "    # 日常生活\n",
    "    \"我们weekend去shopping吧\",\n",
    "    \"这家restaurant的food很nice\",\n",
    "    \"等我five minutes\",\n",
    "    \"这个party太high了\",\n",
    "    \"你要不要去gym运动？\",\n",
    "    # 社交媒体\n",
    "    \"记得给我like和follow\",\n",
    "    \"这个post太cute了\",\n",
    "    \"我们来take个photo\",\n",
    "    \"等下share给你\",\n",
    "    \"这个trending太火了\",\n",
    "    # 科技相关\n",
    "    \"我的phone没电了\",\n",
    "    \"你用什么app打车？\",\n",
    "    \"这个website打不开\",\n",
    "    \"记得backup你的文件\",\n",
    "    \"我的laptop坏了\",\n",
    "]\n",
    "\n",
    "long_code_switching_examples = [\n",
    "    # 工作场景\n",
    "    \"这个quarter我们team的performance很好，完成了所有的KPI，manager说年底会有special bonus，大家都很excited！\",\n",
    "    \"我刚刚参加完一个important的meeting，team leader说我们要开始一个new project，deadline很紧，需要大家一起brainstorm一下。\",\n",
    "    # 学习场景\n",
    "    \"我最近在准备申请PhD program，已经写好了personal statement和research proposal，但是recommendation letter还没有搞定，好stressed啊。\",\n",
    "    \"上周的presentation我表现得不太好，professor说我的research方向需要adjust，还要补充更多的literature review和case study。\",\n",
    "    # 社交场景\n",
    "    \"上周末我们去了一个super nice的rooftop bar，view很漂亮，cocktails很special，而且DJ放的music很好，整个atmosphere都很perfect！\",\n",
    "    \"我follow的那个fashion blogger今天发了一个new post，她share了很多shopping tips，而且还做了一个try-on haul，感觉很useful。\",\n",
    "    # 科技场景\n",
    "    \"我的laptop最近总是自动shutdown，可能是system有问题，我先backup了所有的files，然后准备送去repair，希望不要花太多money。\",\n",
    "    \"这个new app的user interface设计得很user-friendly，而且features都很practical，最重要的是privacy protection做得很好。\",\n",
    "    # 生活场景\n",
    "    \"我们公司附近新开了一家fusion restaurant，他们家的menu很special，combine了Chinese和Western的elements，weekend的brunch很popular。\",\n",
    "    \"最近在follow一个fitness blogger的workout plan，每天都要做cardio和strength training，虽然很tough但是效果还不错。\",\n",
    "]\n",
    "\n",
    "difficult_code_switching_examples = [\n",
    "    # 技术领域\n",
    "    \"我们最近在做machine learning的optimization，用了regularization和cross-validation的方法，但是accuracy还是不够satisfactory。\",\n",
    "    \"这个neural network的architecture太complicated了，需要调整hyperparameters，还要处理overfitting的问题。\",\n",
    "    # 医疗健康\n",
    "    \"医生说我的cardiovascular system需要attention，建议我做一些rehabilitation exercises，还要控制cholesterol的摄入。\",\n",
    "    \"最近做了个comprehensive physical examination，显示immunology indicators都很normal，但是metabolism可能有点问题。\",\n",
    "    # 金融投资\n",
    "    \"这个cryptocurrency的volatility太高了，建议做好risk management，可以考虑portfolio diversification来hedge风险。\",\n",
    "    \"最近market很不stable，很多institutional investors都在做strategic adjustment，retail investors要特别cautious。\",\n",
    "    # 学术研究\n",
    "    \"我的dissertation focus在quantum computing和artificial intelligence的intersection，特别是quantum machine learning的application。\",\n",
    "    \"这个methodology还需要further validation，preliminary results看起来promising，但statistical significance不够。\",\n",
    "    # 商业管理\n",
    "    \"我们需要重新evaluate整个supply chain management system，特别是inventory optimization和logistics efficiency方面。\",\n",
    "    \"根据market analysis，我们的competitive advantage在technological innovation，但organizational structure需要restructuring。\",\n",
    "    # 环境科技\n",
    "    \"这个sustainability project主要研究biodegradable materials在environmental protection中的application。\",\n",
    "    \"我们在做renewable energy的feasibility study，特别关注photovoltaic technology和wind turbine的integration。\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/storage/wyc/eval/test_data_short.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    seed_demo_cases = json.load(f)[\"test_cases\"]\n",
    "\n",
    "len(seed_demo_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_demo_en_pairs = [\n",
    "    (item[\"text\"], item[\"wav_path\"])\n",
    "    for item in seed_demo_cases\n",
    "    if item[\"language\"] == \"en\"\n",
    "]\n",
    "seed_demo_zh_pairs = [\n",
    "    (item[\"text\"], item[\"wav_path\"])\n",
    "    for item in seed_demo_cases\n",
    "    if item[\"language\"] == \"zh\"\n",
    "]\n",
    "\n",
    "len(seed_demo_en_pairs), len(seed_demo_zh_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-lingual, Accented?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Chinese prompt, English target\n",
    "\n",
    "# prompt_text, prompt_speech_wav_path = random.choice(zh_pairs)\n",
    "# target_text, _ = random.choice(en_pairs)\n",
    "\n",
    "prompt_text, prompt_speech_wav_path = random.choice(seed_demo_zh_pairs)\n",
    "target_text, _ = random.choice(seed_demo_en_pairs)\n",
    "\n",
    "print(\"-\" * 20)\n",
    "print(\"[Prompt]\", prompt_text)\n",
    "display_audio_path(prompt_speech_wav_path)\n",
    "print(\"-\" * 20)\n",
    "\n",
    "# print(\"[Synthesized by CosyVoice1]\")\n",
    "# print(\"Target Text: \", target_text)\n",
    "# audio = infer_tts(target_text, prompt_speech_wav_path, prompt_text, model_name=\"cosyvoice\")\n",
    "# display_audio(audio)\n",
    "\n",
    "print(\"[Synthesized by CosyVoice2]\")\n",
    "print(\"Target Text: \", target_text)\n",
    "audio = infer_tts(\n",
    "    target_text, prompt_speech_wav_path, prompt_text, model_name=\"cosyvoice2\"\n",
    ")\n",
    "display_audio(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-\" * 20)\n",
    "print(\"[Prompt]\", prompt_text)\n",
    "display_audio_path(prompt_speech_wav_path)\n",
    "print(\"-\" * 20)\n",
    "\n",
    "print(\"[Synthesized by CosyVoice1]\")\n",
    "print(\"Target Text: \", target_text)\n",
    "audio = infer_tts(\n",
    "    target_text, prompt_speech_wav_path, prompt_text, model_name=\"cosyvoice\"\n",
    ")\n",
    "display_audio(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. English prompt, Chinese target\n",
    "\n",
    "prompt_text, prompt_speech_wav_path = random.choice(en_pairs)\n",
    "target_text, _ = random.choice(zh_pairs)\n",
    "\n",
    "# prompt_text, prompt_speech_wav_path = random.choice(seed_demo_en_pairs)\n",
    "# target_text, _ = random.choice(seed_demo_zh_pairs)\n",
    "\n",
    "print(\"-\" * 20)\n",
    "print(\"[Prompt]\", prompt_text)\n",
    "display_audio_path(prompt_speech_wav_path)\n",
    "print(\"-\" * 20)\n",
    "\n",
    "print(\"[Synthesized]\")\n",
    "print(\"Target Text: \", target_text)\n",
    "audio = infer_tts(target_text, prompt_speech_wav_path, prompt_text)\n",
    "display_audio(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code-switching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_code_switching_text(zh_text, en_text):\n",
    "    # 将中英文文本分别按标点符号切分成短语\n",
    "    zh_phrases = [p.strip() for p in zh_text.replace(\"。\", \"\").split(\"，\") if p.strip()]\n",
    "    en_phrases = [p.strip() for p in en_text.replace(\".\", \"\").split(\",\") if p.strip()]\n",
    "\n",
    "    # 交替组合中英文短语\n",
    "    mixed_phrases = []\n",
    "    max_len = max(len(zh_phrases), len(en_phrases))\n",
    "    for i in range(max_len):\n",
    "        if i < len(zh_phrases):\n",
    "            mixed_phrases.append(zh_phrases[i])\n",
    "        if i < len(en_phrases):\n",
    "            mixed_phrases.append(en_phrases[i])\n",
    "\n",
    "    # 组合成完整句子\n",
    "    return \" \".join(mixed_phrases) + \"。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. English prompt\n",
    "\n",
    "prompt_text, prompt_speech_wav_path = random.choice(en_pairs)\n",
    "target_text = random.choice(difficult_code_switching_examples)\n",
    "\n",
    "print(\"-\" * 20)\n",
    "print(\"[Prompt]\", prompt_text)\n",
    "display_audio_path(prompt_speech_wav_path)\n",
    "print(\"-\" * 20)\n",
    "\n",
    "print(\"[Synthesized]\")\n",
    "print(\"Target Text: \", target_text)\n",
    "audio = infer_tts(target_text, prompt_speech_wav_path, prompt_text)\n",
    "display_audio(audio)\n",
    "\n",
    "print()\n",
    "print(\"*\" * 20)\n",
    "print()\n",
    "\n",
    "prompt_text, prompt_speech_wav_path = random.choice(zh_pairs)\n",
    "print(\"-\" * 20)\n",
    "print(\"[Prompt]\", prompt_text)\n",
    "display_audio_path(prompt_speech_wav_path)\n",
    "print(\"-\" * 20)\n",
    "\n",
    "print(\"[Synthesized]\")\n",
    "print(\"Target Text: \", target_text)\n",
    "audio = infer_tts(target_text, prompt_speech_wav_path, prompt_text)\n",
    "display_audio(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sad_examples = [\n",
    "    # 失落感\n",
    "    \"我的心里空落落的,什么都提不起劲。\",\n",
    "    \"这种无助的感觉让我喘不过气来。\",\n",
    "    \"我真的很难过,眼泪止不住地往下流。\",\n",
    "    # 遗憾与后悔\n",
    "    \"如果当初我做出不同的选择,结局会不会不一样。\",\n",
    "    \"那些错过的机会,现在想起来还是很遗憾。\",\n",
    "    \"我好后悔没能在最后一刻说出那句话。\",\n",
    "    # 思念与想念\n",
    "    \"想起你的时候,心里就像被针扎一样疼。\",\n",
    "    \"每当夜深人静的时候,思念就会涌上心头。\",\n",
    "    \"我多希望这一切都只是一场梦。\",\n",
    "    # 孤独感\n",
    "    \"在人群中我依然感到无比孤单。\",\n",
    "    \"这个世界这么大,却没有一个人能懂我的心。\",\n",
    "    \"有时候觉得自己就像一座孤岛。\",\n",
    "    # 绝望感\n",
    "    \"我感觉人生已经失去了所有的色彩。\",\n",
    "    \"不知道要怎么继续走下去了。\",\n",
    "    \"这种痛苦什么时候才能结束。\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-shot TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_text, prompt_speech_wav_path = random.choice(seed_demo_zh_pairs)\n",
    "target_text = random.choice(sad_examples)\n",
    "\n",
    "print(\"-\" * 20)\n",
    "print(\"[Prompt]\", prompt_text)\n",
    "display_audio_path(prompt_speech_wav_path)\n",
    "print(\"-\" * 20)\n",
    "\n",
    "print(\"[Synthesized by CosyVoice2]\")\n",
    "print(\"Target Text: \", target_text)\n",
    "audio = infer_tts(\n",
    "    target_text, prompt_speech_wav_path, prompt_text, model_name=\"cosyvoice2\"\n",
    ")\n",
    "display_audio(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_text, prompt_speech_wav_path = random.choice(seed_demo_zh_pairs)\n",
    "target_text = random.choice(sad_examples)\n",
    "\n",
    "print(\"-\" * 20)\n",
    "print(\"[Prompt]\", prompt_text)\n",
    "display_audio_path(prompt_speech_wav_path)\n",
    "print(\"-\" * 20)\n",
    "\n",
    "print(\"[Synthesized by CosyVoice2]\")\n",
    "print(\"Target Text: \", target_text)\n",
    "audio = infer_tts(\n",
    "    target_text, prompt_speech_wav_path, prompt_text, model_name=\"cosyvoice2\"\n",
    ")\n",
    "display_audio(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_text, prompt_speech_wav_path = random.choice(en_pairs)\n",
    "target_text = random.choice(sad_examples)\n",
    "\n",
    "print(\"-\" * 20)\n",
    "print(\"[Prompt]\", prompt_text)\n",
    "display_audio_path(prompt_speech_wav_path)\n",
    "print(\"-\" * 20)\n",
    "\n",
    "print(\"[Synthesized by CosyVoice2]\")\n",
    "print(\"Target Text: \", target_text)\n",
    "audio = infer_tts(\n",
    "    target_text, prompt_speech_wav_path, prompt_text, model_name=\"cosyvoice2\"\n",
    ")\n",
    "display_audio(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructed TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_text, prompt_speech_wav_path = random.choice(seed_demo_zh_pairs)\n",
    "# target_text = random.choice(sad_examples)\n",
    "# target_text = \" \".join(sad_examples[:3])\n",
    "target_text = \"我真的很难过,眼泪止不住地往下流。太棒了！我简直开心得要飞起来了！我简直气炸了！这种事情怎么可以发生！\"\n",
    "\n",
    "print(\"-\" * 20)\n",
    "print(\"[Prompt]\", prompt_text)\n",
    "display_audio_path(prompt_speech_wav_path)\n",
    "print(\"-\" * 20)\n",
    "\n",
    "# print(\"[Synthesized by CosyVoice2, zero-shot TTS]\")\n",
    "# print(\"Target Text: \", target_text)\n",
    "# audio = infer_tts(\n",
    "#     target_text, prompt_speech_wav_path, prompt_text, model_name=\"cosyvoice2\"\n",
    "# )\n",
    "# display_audio(audio)\n",
    "\n",
    "print(\"[Synthesized by CosyVoice2, Instruct TTS]\")\n",
    "print(\"Target Text: \", target_text)\n",
    "audio = infer_instruct_tts(\n",
    "    target_text, prompt_speech_wav_path, \"请你非常快速地说\", model_name=\"cosyvoice2\"\n",
    ")\n",
    "display_audio(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosyvoice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
